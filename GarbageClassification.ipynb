{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pSeFw7MCHWF",
        "outputId": "ed305c81-e73d-497f-abef-59beef85afa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 15 images belonging to 6 classes.\n",
            "Found 3 images belonging to 6 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b2_notop.h5\n",
            "\u001b[1m35839040/35839040\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29s/step - accuracy: 0.0667 - loss: 1.9389 - val_accuracy: 1.0000 - val_loss: 1.4619\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.4000 - loss: 1.5702 - val_accuracy: 1.0000 - val_loss: 1.0959\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 1.1269 - val_accuracy: 1.0000 - val_loss: 0.7902\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.8872 - val_accuracy: 1.0000 - val_loss: 0.5522\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.5514 - val_accuracy: 1.0000 - val_loss: 0.3761\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.4323 - val_accuracy: 1.0000 - val_loss: 0.2531\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.3148 - val_accuracy: 1.0000 - val_loss: 0.1699\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.2266 - val_accuracy: 1.0000 - val_loss: 0.1151\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.1594 - val_accuracy: 1.0000 - val_loss: 0.0790\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.1003 - val_accuracy: 1.0000 - val_loss: 0.0556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model saved!\n"
          ]
        }
      ],
      "source": [
        "# ğŸ“Œ STEP 1: Install Required Libraries\n",
        "!pip install -q tensorflow\n",
        "\n",
        "# ğŸ“Œ STEP 2: Import Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetV2B2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "#  Set Parameters\n",
        "IMG_SIZE = (260, 260)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "#  Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Example path (Change to your actual dataset folder in Drive)\n",
        "dataset_path = \"/content/drive/MyDrive/garbage/TrashType_Image_Dataset\"\n",
        "\n",
        "#  Prepare the Dataset\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "#Load EfficientNetV2B2 Model\n",
        "base_model = EfficientNetV2B2(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)\n",
        ")\n",
        "base_model.trainable = False  # freeze base model\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "outputs = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=outputs)\n",
        "\n",
        "#  Compile the Model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the Model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=EPOCHS\n",
        ")\n",
        "\n",
        "# Save the Model\n",
        "model.save('/content/efficientnetv2b2_garbage_classifier.h5')\n",
        "print(\"âœ… Model saved!\")\n",
        "\n",
        "#  Test Prediction Example\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def predict_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=IMG_SIZE)\n",
        "    img_array = image.img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "    class_names = list(train_generator.class_indices.keys())\n",
        "    predicted_class = class_names[np.argmax(predictions)]\n",
        "\n",
        "    print(f\"Predicted Class: {predicted_class}\")\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Prediction: {predicted_class}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "#predict_image(\"/content/drive/MyDrive/test_images/sample.jpg\")\n"
      ]
    }
  ]
}